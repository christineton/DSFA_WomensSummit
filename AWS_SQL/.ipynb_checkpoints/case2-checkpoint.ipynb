{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deriving customer insights with SQL and AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction (5 mts)\n",
    "\n",
    "In this case we'll learn about working large databases that are stored on the cloud and accessed with a database manager. The case will be split into two parts: first, we'll learn the basics of SQL using a smaller data set locally. Then, we'll set up a larger relational database on Amazon Web Services and perform some analysis in the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Introduction to SQL\n",
    "\n",
    "**Business Context.** You are a data analyst at a large financial services firm that sells a diverse portfolio of products. In order to make these sales, the firm relies on a call center where sales agents make calls to current as well as prospective customers. The company would like you to dive into their data to devise strategies to increase their revenue or reduce their costs. Specifically, they would like to double down on their most reliable customers.\n",
    "\n",
    "**Business Problem.** The business would like to answer the following question: **\"What types of customers are most likely to buy our product?**\n",
    "\n",
    "**Analytical Context.** The data is split across 3 tables: \"Agents\", \"Calls\", and \"Customers\", which sit on CSV files. Unlike the last case though, we will first be reading these CSV files into a SQLite database created within Python. You will learn how this database differs from CSV files and how to interact with it using SQL to extract useful insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background (5 min)\n",
    "\n",
    "### Why databases?\n",
    "While we have been dealing with data sitting in CSV files so far, no serious data organization runs their operations off of CSV files on a single person's computer. This practice presents all sorts of hazards, including but not limited to:\n",
    "\n",
    "1. Destruction of that single device\n",
    "2. Destruction of the files on that device\n",
    "3. Inability to connect to that person's device from another device that requires the data\n",
    "4. Inability to store more than a limited amount of data (since a single device doesn't have that much memory)\n",
    "\n",
    "Therefore, our data should be stored elsewhere if we want to reliably access it in the future and, more importantly, share it and work on it with others. The **database** is the classic location where modern organizations have chosen to store their data for professional use. A couple of advantages that databases provide are:\n",
    "\n",
    "- Ability to query only certain recods, instead of fetching and going through the entire csv file\n",
    "- User based access restrictions - Specify what data each of your users can access from the database. This will strengthen the privacy of the data. \n",
    "\n",
    "Daabases have been a topic of research since the late 1960s. Many technology vendors picked up on this and developed databases software for companies to consume. Some of these vendors and products are:\n",
    "\n",
    "1. Microsoft, initially with Microsoft Access and more recently with Microsoft SQL Server\n",
    "2. Oracle, with their Oracle database\n",
    "3. The “PostgreSQL Global Development Group”, with the open-source PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of databases\n",
    "\n",
    "At this point, you might believe that databases can be thought of as a collection of data. This is true, but unfortunately it is not that simple. Data cannot simply be thrown in a database the same way you throw your socks in your sock drawer. The data that you wish to store in your database must follow some patterns which are determined by the **database type** you wish to store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relational databases\n",
    "\n",
    "The most common database type is called a **relational database**, and the systems that manage these kinds of databases are called **Relational Database Management Systems (RDBMS)**. Relational databases date back to the early 1970s and can be considered the first type of database ever conceived.\n",
    "\n",
    "Relational databases deal with “relational data”, which is a fancy way to say “tabular” data. This kind of dataset consists of rows and columns (i.e. tables) where each row corresponds to an observation and each column corresponds to an attribute of that observation. So, for example, if we go back to the example where we were keeping track of our friends and their phones, each row on the file (or table) represents one friend and each column represents the information we want to track about that friend (name and phone number). The cell on the intersection of the row and column contains the actual data. Relational data is manipulated using a specific language called **SQL (Structured Query Language)**, which we will learn about soon.\n",
    "\n",
    "A simple way to conceptualize a table inside a relational database is as a CSV file “copied” to the database. In fact, many databases offer that possibility (assuming your file is correctly formatted, of course)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NoSQL databases\n",
    "\n",
    "Around 20 years ago, with the advent of the internet and the necessity to store and process unstructured data (i.e. data that does not fit well in the row-by-column paradigm), developers started to discuss another type of database, which eventually ended up being referred to as a **NoSQL database**. As the name implies, these databases do not rely on SQL and are not relational. They are also built with more “relaxed” rules compared to their predecessors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Basics (20 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is this \"SQL\" thing?\n",
    "\n",
    "Just like data can't really survive without a database, a database can't be utilized without SQL. SQL is used for a wide variety of tasks, including but not limited to extracting data, creating the internal structure of a database (in the form of tables), and reading and writing data to these tables.\n",
    "\n",
    "In this case, we will be writing SQL queries using the `SQLAlchemy` package in Python. This allows you to directly interface with relational databases without exiting the Python environment, while using syntax that is identical to what you would write outside of Python. Run the code below to set up this framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "#maximum number of rows to display\n",
    "pd.options.display.max_rows = 10\n",
    "\n",
    "engine=create_engine('sqlite://')\n",
    "df = pd.read_csv('customers.csv').to_sql('customers', engine, if_exists='replace', index=False)\n",
    "df = pd.read_csv('agents.csv').to_sql('agents', engine, if_exists='replace', index=False)\n",
    "df = pd.read_csv('calls.csv').to_sql('calls', engine, if_exists='replace', index=False)\n",
    "\n",
    "def runQuery(sql):\n",
    "    result = engine.connect().execute((text(sql)))\n",
    "    return pd.DataFrame(result.fetchall(), columns=result.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what the tables look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>name</th>\n",
       "      <th>occupation</th>\n",
       "      <th>email</th>\n",
       "      <th>company</th>\n",
       "      <th>phonenumber</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>David Melton</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>DMelton@zoho.com</td>\n",
       "      <td>Morris, Winters and Ramirez</td>\n",
       "      <td>409-093-0748</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Michael Gonzalez</td>\n",
       "      <td>Student</td>\n",
       "      <td>Gonzalez_Michael@yahoo.com</td>\n",
       "      <td>Hernandez and Sons</td>\n",
       "      <td>231-845-0673</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amanda Wilson</td>\n",
       "      <td>Student</td>\n",
       "      <td>Amanda.Wilson75@verizon.com</td>\n",
       "      <td>Mooney, West and Hansen</td>\n",
       "      <td>844-276-4552</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Robert Thomas</td>\n",
       "      <td>Engineer, structural</td>\n",
       "      <td>RThomas@xfinity.com</td>\n",
       "      <td>Johnson-Gordon</td>\n",
       "      <td>410-404-8000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Eddie Hall</td>\n",
       "      <td>Surgeon</td>\n",
       "      <td>EddieHall@outlook.com</td>\n",
       "      <td>Dawson LLC</td>\n",
       "      <td>872-287-2196</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>Ashley Young</td>\n",
       "      <td>Student</td>\n",
       "      <td>Ashley_Y@xfinity.com</td>\n",
       "      <td>Esparza-Johnson</td>\n",
       "      <td>751-654-6719</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>Mr. Steven Smith</td>\n",
       "      <td>Engineer, structural</td>\n",
       "      <td>Mr..Smith@zoho.com</td>\n",
       "      <td>Hensley-Odom</td>\n",
       "      <td>279-898-4565</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>Mark Smith</td>\n",
       "      <td>Engineer, control and instrumentation</td>\n",
       "      <td>Mark_S@yahoo.com</td>\n",
       "      <td>Fisher LLC</td>\n",
       "      <td>563-382-1868</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>Jeffrey Carrillo</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>JeffreyCarrillo@yahoo.com</td>\n",
       "      <td>Morgan LLC</td>\n",
       "      <td>223-784-2416</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>Karen Barber</td>\n",
       "      <td>Doctor, general practice</td>\n",
       "      <td>Karen.Barber20@yandex.com</td>\n",
       "      <td>Nelson, Joseph and Fowler</td>\n",
       "      <td>512-703-6189</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     customerid              name                             occupation  \\\n",
       "0             0      David Melton                             Unemployed   \n",
       "1             1  Michael Gonzalez                                Student   \n",
       "2             2     Amanda Wilson                                Student   \n",
       "3             3     Robert Thomas                   Engineer, structural   \n",
       "4             4        Eddie Hall                                Surgeon   \n",
       "..          ...               ...                                    ...   \n",
       "995         995      Ashley Young                                Student   \n",
       "996         996  Mr. Steven Smith                   Engineer, structural   \n",
       "997         997        Mark Smith  Engineer, control and instrumentation   \n",
       "998         998  Jeffrey Carrillo                             Unemployed   \n",
       "999         999      Karen Barber               Doctor, general practice   \n",
       "\n",
       "                           email                      company   phonenumber  \\\n",
       "0               DMelton@zoho.com  Morris, Winters and Ramirez  409-093-0748   \n",
       "1     Gonzalez_Michael@yahoo.com           Hernandez and Sons  231-845-0673   \n",
       "2    Amanda.Wilson75@verizon.com      Mooney, West and Hansen  844-276-4552   \n",
       "3            RThomas@xfinity.com               Johnson-Gordon  410-404-8000   \n",
       "4          EddieHall@outlook.com                   Dawson LLC  872-287-2196   \n",
       "..                           ...                          ...           ...   \n",
       "995         Ashley_Y@xfinity.com              Esparza-Johnson  751-654-6719   \n",
       "996           Mr..Smith@zoho.com                 Hensley-Odom  279-898-4565   \n",
       "997             Mark_S@yahoo.com                   Fisher LLC  563-382-1868   \n",
       "998    JeffreyCarrillo@yahoo.com                   Morgan LLC  223-784-2416   \n",
       "999    Karen.Barber20@yandex.com    Nelson, Joseph and Fowler  512-703-6189   \n",
       "\n",
       "     Age  \n",
       "0     16  \n",
       "1     19  \n",
       "2     18  \n",
       "3     25  \n",
       "4     30  \n",
       "..   ...  \n",
       "995   19  \n",
       "996   26  \n",
       "997   29  \n",
       "998   15  \n",
       "999   24  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the customers table\n",
    "queryd1 = \"\"\"SELECT *\n",
    "FROM customers\n",
    "\"\"\"\n",
    "runQuery(queryd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>callid</th>\n",
       "      <th>agentid</th>\n",
       "      <th>customerid</th>\n",
       "      <th>pickedup</th>\n",
       "      <th>duration</th>\n",
       "      <th>productsold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>691</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>629</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>318</td>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9935</th>\n",
       "      <td>9995</td>\n",
       "      <td>6</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9936</th>\n",
       "      <td>9996</td>\n",
       "      <td>0</td>\n",
       "      <td>731</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9937</th>\n",
       "      <td>9997</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9938</th>\n",
       "      <td>9998</td>\n",
       "      <td>5</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9939</th>\n",
       "      <td>9999</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9940 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      callid  agentid  customerid  pickedup  duration  productsold\n",
       "0          0       10         179         0         0            0\n",
       "1          1        5         691         1       116            0\n",
       "2          2       10          80         1       165            0\n",
       "3          3        6         629         1       128            0\n",
       "4          4        8         318         1       205            0\n",
       "...      ...      ...         ...       ...       ...          ...\n",
       "9935    9995        6          92         1       103            0\n",
       "9936    9996        0         731         1       188            0\n",
       "9937    9997        4          53         1       152            0\n",
       "9938    9998        5         260         0         0            0\n",
       "9939    9999        3          31         1       250            1\n",
       "\n",
       "[9940 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the calls table\n",
    "queryd2 = \"\"\"SELECT *\n",
    "FROM calls\n",
    "\"\"\"\n",
    "runQuery(queryd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the `customers` table\n",
    "\n",
    "The most important thing you will ever do in SQL is extract a subset of the data from a SQL table based on a set of rules. This is accomplished using the following statement syntax:\n",
    "\n",
    "1. Start with the keyword `SELECT`\n",
    "2. Follow with the names of the columns you want to select, separated by commas (alternatively, you can use the `*` symbol to indicate you wish to select all columns)\n",
    "3. Follow with the keyword `FROM`\n",
    "4. Finish with the name of the table you wish to select data from\n",
    "\t\n",
    "Additionally, you can use the `WHERE` clause to only return results which satisfy certain conditions (similar to how code within Python if-then blocks only execute if the associated conditions are true). `WHERE` clauses immediately follow the table name you want to select data from.\n",
    "\n",
    "Since the firm wants to dig deeper into its customers, let's start by pulling some of their data out of our files; namely, information about customers who are not unemployed (and therefore are more likely to buy from us)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: (5 min)\n",
    "\n",
    "Write a query that selects the customer ID and name from the `customer` table, only showing results for customers who are not unemployed. Remember to write your query as a multi-line string (enclosed within a pair of triple quotes `\"\"\"`) and pass it to the `runQuery()` function defined in the framework above to check your work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**. One possible solution is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT customerid, name\n",
    "FROM customers\n",
    "WHERE occupation != 'Unemployed'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Michael Gonzalez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Amanda Wilson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Robert Thomas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Eddie Hall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Maria Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>994</td>\n",
       "      <td>Ruben Steele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>995</td>\n",
       "      <td>Ashley Young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>996</td>\n",
       "      <td>Mr. Steven Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>997</td>\n",
       "      <td>Mark Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>999</td>\n",
       "      <td>Karen Barber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     customerid              name\n",
       "0             1  Michael Gonzalez\n",
       "1             2     Amanda Wilson\n",
       "2             3     Robert Thomas\n",
       "3             4        Eddie Hall\n",
       "4             6     Maria Johnson\n",
       "..          ...               ...\n",
       "755         994      Ruben Steele\n",
       "756         995      Ashley Young\n",
       "757         996  Mr. Steven Smith\n",
       "758         997        Mark Smith\n",
       "759         999      Karen Barber\n",
       "\n",
       "[760 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1 = \"\"\"SELECT customerid, name\n",
    "FROM customers\n",
    "WHERE occupation != 'Unemployed'\"\"\"\n",
    "runQuery(query1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, for names, it's sensible to try to list them in alphabetical order. SQL allows us to do this rather easily with the `ORDER BY` statement. This is then followed by a comma-separated list of columns on which you want to order your results (columns that come first take priority in the subsequent ordering). Optionally, you can then append the keyword `ASC` or `DESC` (short for ascending and descending, respectively) after each column to determine the ordering type (e.g. alphabetical or reverse-alphabetical for a string column).\n",
    "\n",
    "We can also use the `AS` statment to change the name of a column returned by your query. However, this change is only temporary and is only valid for that particular query. For example, we can rename the `name` column to `customername` and order it alphabetically. This operation is known as **aliasing**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT customerid, name AS customername\n",
    "FROM customers\n",
    "WHERE occupation != 'Unemployed'\n",
    "ORDER BY customername\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>customername</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>900</td>\n",
       "      <td>Aaron Gutierrez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>622</td>\n",
       "      <td>Aaron Rose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>Adam Ward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>786</td>\n",
       "      <td>Alan Chambers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>985</td>\n",
       "      <td>Alan Mitchell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>699</td>\n",
       "      <td>Willie Greene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>715</td>\n",
       "      <td>Yesenia Wright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>952</td>\n",
       "      <td>Yolanda White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>421</td>\n",
       "      <td>Zachary Ruiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>392</td>\n",
       "      <td>Zachary Wilson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     customerid     customername\n",
       "0           900  Aaron Gutierrez\n",
       "1           622       Aaron Rose\n",
       "2           226        Adam Ward\n",
       "3           786    Alan Chambers\n",
       "4           985    Alan Mitchell\n",
       "..          ...              ...\n",
       "755         699    Willie Greene\n",
       "756         715   Yesenia Wright\n",
       "757         952    Yolanda White\n",
       "758         421     Zachary Ruiz\n",
       "759         392   Zachary Wilson\n",
       "\n",
       "[760 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query2 = \"\"\"SELECT customerid, name AS customername\n",
    "FROM customers\n",
    "WHERE occupation != 'Unemployed'\n",
    "ORDER BY customername\"\"\"\n",
    "runQuery(query2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a great first step; however, while producing the list of customers that are not unemployed, you inevitably spend a lot of time looking at the different professions your customers have and realize how often engineers appear in your database. You know that engineering jobs tend to command higher salaries these days, so you decide to try to extract a list of all the unique types of engineering jobs that are represented in your database. To ensure that you don't get duplicate job titles in your query results, you'll need to write the keyword `DISTINCT` immediately after `SELECT` in your query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: (5 min)\n",
    "\n",
    "Write a query which produces a list, in alphabetical order, of all the distinct occupations in the `customer` table that contain the word \"Engineer\".\n",
    "\n",
    "(Hint: The `LIKE` operator can be used when you want to look for similar values. It is included as part of a `WHERE` clause. It needs to be complemented with the `%` symbol, which is a wild card that represents zero, one, or multiple characters. For example, one valid `WHERE` clause utilizing the `LIKE` operator is `WHERE name LIKE 'Matt%'`, which would return any results where the person's name starts with the word \"Matt\"; e.g. \"Matt\" or \"Matteo\" or \"Matthew\", etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT DISTINCT occupation\n",
    "FROM customers\n",
    "WHERE occupation LIKE '%Engineer%'\n",
    "ORDER BY occupation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chemical engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electrical engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Engineer, aeronautical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Engineer, agricultural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Engineer, automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Engineer, production</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Engineer, site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Engineer, structural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Engineer, technical sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Engineer, water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   occupation\n",
       "0           Chemical engineer\n",
       "1         Electrical engineer\n",
       "2      Engineer, aeronautical\n",
       "3      Engineer, agricultural\n",
       "4        Engineer, automotive\n",
       "..                        ...\n",
       "24       Engineer, production\n",
       "25             Engineer, site\n",
       "26       Engineer, structural\n",
       "27  Engineer, technical sales\n",
       "28            Engineer, water\n",
       "\n",
       "[29 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query3 = \"\"\"SELECT DISTINCT occupation\n",
    "FROM customers\n",
    "WHERE occupation LIKE '%Engineer%'\n",
    "ORDER BY occupation\"\"\"\n",
    "runQuery(query3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, one of your marketing colleagues tells you that people who are 30 or older will have a higher probability of buying your product (presumably because by that point they have more disposable income and savings). You don't want to take your colleague's word for granted, so you decide not to completely ignore people under 30, but instead to add that information on the report regarding the person’s age, so that the agent making the subsequent call can decide how they want to use that information. However, due to privacy concerns, you also cannot share the person's exact age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: (5 min)\n",
    "\n",
    "Write a query that retuns the customer ID, their name, and a column `Over30` containing \"Yes\" if the customer is more than 30 years of age and \"No\" if not.\n",
    "\n",
    "(Hint: You will need to use the `CASE-END` clause. The `CASE-END` clause can be used to evaluate conditional statements and returns a value once a condition is met (similar to an if-then-else clause in Python). If no conditions are true, it returns the value in the ELSE clause (or NULL if there is no ELSE statement). For example:\n",
    "\n",
    "```SQL\n",
    "CASE\n",
    "    WHEN name = \"Matt\" THEN 'Yes'\n",
    "    WHEN name = \"Matteo\" THEN 'Maybe'\n",
    "    ELSE 'No'\n",
    "END\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT customerid, name,\n",
    "    CASE\n",
    "        WHEN age >= 30 THEN 'Yes'\n",
    "        WHEN age <  30 THEN 'No'\n",
    "        ELSE 'Missing Data'\n",
    "    END AS Over30\n",
    "FROM customers\n",
    "ORDER BY name DESC\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>name</th>\n",
       "      <th>Over30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>392</td>\n",
       "      <td>Zachary Wilson</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>986</td>\n",
       "      <td>Zachary Stevenson</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>421</td>\n",
       "      <td>Zachary Ruiz</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>Zachary Howe</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>883</td>\n",
       "      <td>Zachary Anderson</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>65</td>\n",
       "      <td>Adam Jimenez</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>622</td>\n",
       "      <td>Aaron Rose</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>145</td>\n",
       "      <td>Aaron Mcintyre</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>461</td>\n",
       "      <td>Aaron Hendrix</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>900</td>\n",
       "      <td>Aaron Gutierrez</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     customerid               name Over30\n",
       "0           392     Zachary Wilson    Yes\n",
       "1           986  Zachary Stevenson     No\n",
       "2           421       Zachary Ruiz    Yes\n",
       "3            18       Zachary Howe     No\n",
       "4           883   Zachary Anderson     No\n",
       "..          ...                ...    ...\n",
       "995          65       Adam Jimenez     No\n",
       "996         622         Aaron Rose     No\n",
       "997         145     Aaron Mcintyre     No\n",
       "998         461      Aaron Hendrix     No\n",
       "999         900    Aaron Gutierrez    Yes\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query4 = \"\"\"SELECT customerid, name,\n",
    "    CASE\n",
    "        WHEN age >= 30 THEN 'Yes'\n",
    "        WHEN age <  30 THEN 'No'\n",
    "        ELSE 'Missing Data'\n",
    "    END AS Over30\n",
    "FROM customers\n",
    "ORDER BY name DESC\"\"\"\n",
    "runQuery(query4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now modify Exercise 3 so that the query only returns customers who work in an engineering profession:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT customerid, name,\n",
    "    CASE\n",
    "        WHEN age >= 30 THEN 'Yes'\n",
    "        WHEN age <  30 THEN 'No'\n",
    "        ELSE 'Missing Data'\n",
    "    END AS Over30\n",
    "FROM customers\n",
    "WHERE occupation LIKE '%Engineer%'\n",
    "ORDER BY name DESC\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>name</th>\n",
       "      <th>Over30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>421</td>\n",
       "      <td>Zachary Ruiz</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>952</td>\n",
       "      <td>Yolanda White</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>699</td>\n",
       "      <td>Willie Greene</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>973</td>\n",
       "      <td>William Jackson</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>966</td>\n",
       "      <td>William Garcia</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>918</td>\n",
       "      <td>Alison Vaughan</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>568</td>\n",
       "      <td>Alice Lee</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>432</td>\n",
       "      <td>Alexis Riddle</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>985</td>\n",
       "      <td>Alan Mitchell</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>622</td>\n",
       "      <td>Aaron Rose</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     customerid             name Over30\n",
       "0           421     Zachary Ruiz    Yes\n",
       "1           952    Yolanda White     No\n",
       "2           699    Willie Greene    Yes\n",
       "3           973  William Jackson    Yes\n",
       "4           966   William Garcia     No\n",
       "..          ...              ...    ...\n",
       "356         918   Alison Vaughan    Yes\n",
       "357         568        Alice Lee     No\n",
       "358         432    Alexis Riddle     No\n",
       "359         985    Alan Mitchell    Yes\n",
       "360         622       Aaron Rose     No\n",
       "\n",
       "[361 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query5 = \"\"\"SELECT customerid, name,\n",
    "    CASE\n",
    "        WHEN age >= 30 THEN 'Yes'\n",
    "        WHEN age <  30 THEN 'No'\n",
    "        ELSE 'Missing Data'\n",
    "    END AS Over30\n",
    "FROM customers\n",
    "WHERE occupation LIKE '%Engineer%'\n",
    "ORDER BY name DESC\"\"\"\n",
    "runQuery(query5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating customer conversion rates (30 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate whether our hypotheses about engineers and age are true (for example, engineers exhibit higher product sales conversion rates, and perhaps engineers over 30 tend to exhibit an even higher conversion rate), we will need to use two tables: `calls` and `customers`. This is because the column `productsold` lies only in the `calls` table, yet information about customer professions and age only lie in the `customers` table.\n",
    "\n",
    "`SELECT` commands are not restricted to a single table. In fact, theoretically, there is no limit to the number of tables that you can extract data from in a single SQL query. Let's introduce some new concepts that are relevant once we go beyond a single table.\n",
    "\n",
    "**Primary and foreign keys** are very important concepts that need to be understood by any database professional. Primary keys:\n",
    "\n",
    "1. Uniquely identify a record in the table. Their name usually includes the word \"id\"\n",
    "    * For example, `customerid` is the primary key of the `customers` table, `agentid` is the primary key of the `agents` table, and `callid` is the primary key of the `calls` table    \n",
    "2. Do not accept null values. And they shouldn't, because they are being used to identify the record\n",
    "3. Are limited to one per table\n",
    "\n",
    "On the other hand, foreign keys:\n",
    "\n",
    "1. Are a field in the table that is the primary key in another table\n",
    "2. Can accept null values\n",
    "3. Are not limited in any way per table\n",
    "    * For example, the `calls` tables has 2 foreign keys: `agentid` and `customerid` pointing to the `agents` and `customers` tables, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting call data for customers working in engineering professions (10 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first extract the relevant data so we can perform this analysis. Here, a `JOIN` clause will come in handy. A `JOIN` clause consists of two parts:\n",
    "\n",
    "1. The base `JOIN` statement, which is of the form `[Table 1] JOIN [Table 2]`. This performs a Cartesian product on the 2 tables being joined. For example, if we have Table A with 5 rows, and Table 5 with 3 rows, their Cartesian product will return 15 rows (5 x 3)\n",
    "2. A `JOIN` criteria, which filters the Cartesian product's results, beginning with the `ON` keyword\n",
    "\n",
    "Here is an example of a `JOIN` criteria in action, which is telling us to only give combinations of rows where the agent ID matches in both tables:\n",
    "\n",
    "```SQL\n",
    "SELECT callid, a.agentid, name\n",
    "FROM calls c\n",
    "JOIN agents a ON c.agentid = a.agentid\n",
    "ORDER BY name DESC\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>callid</th>\n",
       "      <th>agentid</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>Todd Morrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>Todd Morrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>Todd Morrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>Todd Morrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>Todd Morrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9934</th>\n",
       "      <td>9985</td>\n",
       "      <td>10</td>\n",
       "      <td>Agent X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9935</th>\n",
       "      <td>9986</td>\n",
       "      <td>10</td>\n",
       "      <td>Agent X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9936</th>\n",
       "      <td>9991</td>\n",
       "      <td>10</td>\n",
       "      <td>Agent X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9937</th>\n",
       "      <td>9992</td>\n",
       "      <td>10</td>\n",
       "      <td>Agent X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9938</th>\n",
       "      <td>9994</td>\n",
       "      <td>10</td>\n",
       "      <td>Agent X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9939 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      callid  agentid         name\n",
       "0         12        3  Todd Morrow\n",
       "1         28        3  Todd Morrow\n",
       "2         32        3  Todd Morrow\n",
       "3         50        3  Todd Morrow\n",
       "4         60        3  Todd Morrow\n",
       "...      ...      ...          ...\n",
       "9934    9985       10      Agent X\n",
       "9935    9986       10      Agent X\n",
       "9936    9991       10      Agent X\n",
       "9937    9992       10      Agent X\n",
       "9938    9994       10      Agent X\n",
       "\n",
       "[9939 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query6 = \"\"\"SELECT callid, a.agentid, name\n",
    "FROM calls c\n",
    "JOIN agents a ON c.agentid = a.agentid\n",
    "ORDER BY name DESC\"\"\"\n",
    "runQuery(query6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that:\n",
    "\n",
    "1. `c` and `a` are aliases to the `calls` and `agents` tables to avoid having to type the table name every time. Unlike with column aliasing earlier, we do not need the `AS` keyword here\n",
    "2. We write `a.agentid` instead of `agentid` in the SELECT statement – this is because the `agentid` column exists in both tables, so we have to tell the database which one to get the result from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: (5 min)\n",
    "\n",
    "Write a query which returns all calls made out to customers in the engineering profession, and shows whether they are over or under 30 as well as whether they ended up purchasing the product from that call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT callid, cu.customerid, name, productsold,\n",
    "    CASE\n",
    "        WHEN age >= 30 THEN 'Yes'\n",
    "        WHEN age <  30 THEN 'No'\n",
    "        ELSE 'Missing Data'\n",
    "    END AS Over30\n",
    "FROM customers cu\n",
    "JOIN calls ca ON ca.customerid = cu.customerid\n",
    "WHERE occupation LIKE '%Engineer%'\n",
    "ORDER BY name DESC\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>callid</th>\n",
       "      <th>customerid</th>\n",
       "      <th>name</th>\n",
       "      <th>productsold</th>\n",
       "      <th>Over30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2049</td>\n",
       "      <td>421</td>\n",
       "      <td>Zachary Ruiz</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2960</td>\n",
       "      <td>421</td>\n",
       "      <td>Zachary Ruiz</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3365</td>\n",
       "      <td>421</td>\n",
       "      <td>Zachary Ruiz</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3386</td>\n",
       "      <td>421</td>\n",
       "      <td>Zachary Ruiz</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4332</td>\n",
       "      <td>421</td>\n",
       "      <td>Zachary Ruiz</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3614</th>\n",
       "      <td>6444</td>\n",
       "      <td>622</td>\n",
       "      <td>Aaron Rose</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>7994</td>\n",
       "      <td>622</td>\n",
       "      <td>Aaron Rose</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>8811</td>\n",
       "      <td>622</td>\n",
       "      <td>Aaron Rose</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3617</th>\n",
       "      <td>9524</td>\n",
       "      <td>622</td>\n",
       "      <td>Aaron Rose</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3618</th>\n",
       "      <td>9965</td>\n",
       "      <td>622</td>\n",
       "      <td>Aaron Rose</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3619 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      callid  customerid          name  productsold Over30\n",
       "0       2049         421  Zachary Ruiz            0    Yes\n",
       "1       2960         421  Zachary Ruiz            0    Yes\n",
       "2       3365         421  Zachary Ruiz            0    Yes\n",
       "3       3386         421  Zachary Ruiz            1    Yes\n",
       "4       4332         421  Zachary Ruiz            0    Yes\n",
       "...      ...         ...           ...          ...    ...\n",
       "3614    6444         622    Aaron Rose            1     No\n",
       "3615    7994         622    Aaron Rose            0     No\n",
       "3616    8811         622    Aaron Rose            0     No\n",
       "3617    9524         622    Aaron Rose            1     No\n",
       "3618    9965         622    Aaron Rose            0     No\n",
       "\n",
       "[3619 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query7 = \"\"\"SELECT callid, cu.customerid, name, productsold,\n",
    "    CASE\n",
    "        WHEN age >= 30 THEN 'Yes'\n",
    "        WHEN age <  30 THEN 'No'\n",
    "        ELSE 'Missing Data'\n",
    "    END AS Over30\n",
    "FROM customers cu\n",
    "JOIN calls ca ON ca.customerid = cu.customerid\n",
    "WHERE occupation LIKE '%Engineer%'\n",
    "ORDER BY name DESC\"\"\"\n",
    "runQuery(query7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the call conversion data (20 min)\n",
    "\n",
    "Now, we want to determine whether or not customers in our desired cohort exhibit a higher sales conversion rate compared to the overall population of customers. A reasonable way to do this is to count the total number of calls to this cohort which resulted in a sale, and divide that by the total number of calls to this cohort (whether or not they resulted in a sale) to get a percentage, and then compare that with the percentage we compute from the `calls` table overall.\n",
    "\n",
    "However, to compute these figures, we'll need to learn a bit about **aggregation functions**. An aggregation function allows you to perform a calculation on a set of values to return a single value, essentially computing some sort of summary statistic.\n",
    "\n",
    "The following are the most commonly used SQL aggregate functions:\n",
    "\n",
    "1. `AVG()` – calculates the average of a set of values\n",
    "2. `COUNT()` – counts rows in a specified table or view\n",
    "3. `MIN()` – gets the minimum value in a set of values\n",
    "4. `MAX()` – gets the maximum value in a set of values\n",
    "5. `SUM()` – calculates the sum of values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: (10 min)\n",
    "\n",
    "Write two queries: one that computes the total sales and total calls made to customers in the engineering profession, and one that computes the same metrics for the entire customer base. What can you conclude regarding the conversion rate within the engineering customers vs. the overall customer base?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT SUM(productsold) AS totalsales, COUNT(*) AS ncalls\n",
    "FROM customers cu\n",
    "JOIN calls ca ON ca.customerid = cu.customerid\n",
    "WHERE occupation LIKE '%Engineer%'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalsales</th>\n",
       "      <th>ncalls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>760</td>\n",
       "      <td>3619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   totalsales  ncalls\n",
       "0         760    3619"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query8 = \"\"\"SELECT SUM(productsold) AS totalsales, COUNT(*) AS ncalls\n",
    "FROM customers cu\n",
    "JOIN calls ca ON ca.customerid = cu.customerid\n",
    "WHERE occupation LIKE '%Engineer%'\"\"\"\n",
    "runQuery(query8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT SUM(productsold) AS totalsales, COUNT(*) AS ncalls\n",
    "FROM customers cu\n",
    "JOIN calls ca ON ca.customerid = cu.customerid\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalsales</th>\n",
       "      <th>ncalls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2084</td>\n",
       "      <td>9925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   totalsales  ncalls\n",
       "0        2084    9925"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query9 = \"\"\"SELECT SUM(productsold) AS totalsales, COUNT(*) AS ncalls\n",
    "FROM customers cu\n",
    "JOIN calls ca ON ca.customerid = cu.customerid\"\"\"\n",
    "runQuery(query9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conversion rate for both groups is ~20.9%, indicating that engineers are not more likely to purchase our products than the overall population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: (5 min)\n",
    "\n",
    "Write a query that computes the total sales and total calls made to customers over the age of 30. Is there a notable difference between the conversion ratio here and that of the overall customer base?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT SUM(productsold) AS totalsales, COUNT(*) AS ncalls\n",
    "FROM customers cu\n",
    "JOIN calls ca ON ca.customerid = cu.customerid\n",
    "WHERE age >= 30\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalsales</th>\n",
       "      <th>ncalls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>659</td>\n",
       "      <td>3096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   totalsales  ncalls\n",
       "0         659    3096"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query10 = \"\"\"SELECT SUM(productsold) AS totalsales, COUNT(*) AS ncalls\n",
    "FROM customers cu\n",
    "JOIN calls ca ON ca.customerid = cu.customerid\n",
    "WHERE age >= 30\"\"\"\n",
    "runQuery(query10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conversion rate is ~21.1% vs. the overall ~20.9%. There may be some difference, but it is quite small so we would need to run statistical significance tests in order to validate this. Since that's not the focus of this case, we'll skip that for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: (5 min)\n",
    "\n",
    "How about if you look at the sales conversion rate for engineers over the age of 30?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT SUM(productsold) AS totalsales, COUNT(*) AS ncalls\n",
    "FROM customers cu\n",
    "JOIN calls ca ON ca.customerid = cu.customerid\n",
    "WHERE occupation LIKE '%Engineer%' AND age >= 30\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalsales</th>\n",
       "      <th>ncalls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>376</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   totalsales  ncalls\n",
       "0         376    1816"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query11 = \"\"\"SELECT SUM(productsold) AS totalsales, COUNT(*) AS ncalls\n",
    "FROM customers cu\n",
    "JOIN calls ca ON ca.customerid = cu.customerid\n",
    "WHERE occupation LIKE '%Engineer%' AND age >= 30\"\"\"\n",
    "runQuery(query11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we actually observe the opposite pattern – the conversion rate is only ~20.5%.\n",
    "\n",
    "From these numbers, we can conclude that a customer's status as an engineering professional has no positive effect on their conversion rate. On the other hand, having an age of at least 30 MAY have some effect; however, we would need to do more in-depth statistical testing to determine this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transition (10 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is AWS?\n",
    "\n",
    "Amazon Web Services (AWS) is a cloud service from Amazon, which provides services in the form of building blocks. These building blocks can be used to create and deploy any type of application in the cloud.\n",
    "\n",
    "These services are designed to work with each other, and result in applications which are sophisticated and highly scalable. The following are the most commonly used domains:\n",
    "\n",
    "- The **Compute** domain includes services related to compute workloads. Services in this domain can be used to run computationally intensive or repetitive tasks that you don't want to run locally\n",
    "- The **Database** domain is used for database related workloads. Services in this domain provide cost-efficient and resizable capacity and can automate time-consuming administration tasks such as provisioning hardware, setting up the database, patching, and making backups\n",
    "- The **Migration** domain is used for transferring data to or from the AWS Infrastructure\n",
    "- The **Networking and Content Delivery** domain is used for isolating your network infrastructure, and content delivery is used for faster delivery of content\n",
    "- The **Management Tools** domain consists of services which are used to manage other services in AWS\n",
    "- The **Security & Identity, Compliance** domain consist of services which are used to manage to authenticate and provide security to your AWS resources\n",
    "- The **Messaging** domain consists of services which are used for queuing, notifying or emailing messages\n",
    "\n",
    "In this case we'll focus on the database domain, specifically the RDS service. You can find more information about other AWS services in the Additional Resources section at the end of the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log In! \n",
    "\n",
    "Start by signing in to [AWS](https://signin.aws.amazon.com/signin?redirect_uri=https%3A%2F%2Fconsole.aws.amazon.com%2Fconsole%2Fhome%3Fnc2%3Dh_ct%26src%3Dheader-signin%26state%3DhashArgs%2523%26isauthcode%3Dtrue&client_id=arn%3Aaws%3Aiam%3A%3A015428540659%3Auser%2Fhomepage&forceMobileApp=0) using your root user credentials. If you have not created your own AWS account, please consult with your TA to obtain the relevant instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Two: Analyzing Net Promoter Score (NPS) data with AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction (5 min)\n",
    "\n",
    "**Business Context.** You are a data scientist at a new but fast-growing startup. The startup released its first product 12 months ago and has been tracking Net Promoter Score (NPS) over its growing customer base since the product's launch.\n",
    "\n",
    "The team assumes that the NPS score is correlated to the product stability and feature-completeness and that the product has been getting more stable and complete over time. They also realize that there have been some hiccups along the way, and they assume that NPS has therefore fluctuated up and down.\n",
    "\n",
    "**Business Problem.** The startup wants you to investigate the data and answering the following question: **\"Has our NPS improved over time? And has our average NPS decreased in specific periods over the last 12 months?\"**\n",
    "\n",
    "**Analytical Context.** In this part of the case, you will be working with a large dataset – so large that your personal laptop is not powerful enough to run heavy SQL queries on it (the startup is stingy and doesn't provide employees with hardware – luckily they have free cloud credits though!). Instead, you will be working with a powerful PostgreSQL database in the cloud (on Amazon Web Services), and uploading the data there for remote processing. We'll connect to the remote database and have the remote machine run the resource-intensive queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Net Promoter Score (NPS) (10 min)\n",
    "\n",
    "NPS is a metric to measure customer satisfaction. You've probably seen pop-ups online, or received surveys via email, asking you \"Would you recommend [product] to a friend or family member?\" and giving you the option to respond with a number between 0 and 10. That's someone collecting information to calculate their NPS.\n",
    "\n",
    "![nps Example Survey](images/nps-example-survey.png)\n",
    "\n",
    "The basic idea is simple - customers who respond with high ratings are more likely to promote your product to other potential customers. Customers who give low ratings are unhappy and are unlikely to help you grow your customer base. If you ask enough people at different time periods, you can track customer satisfaction over time and see how this correlates to product development and other aspects of your business that are within your control. \n",
    "\n",
    "NPS categorizes users into three groups based on the ratings that they leave. This is done as follows:\n",
    "\n",
    "1. Users who leave a rating of 0 - 6 are regarded as \"detractors\"\n",
    "2. Users who leave a rating of 7 or 8 are regarded as \"passives\"\n",
    "3. Users who leave a rating of 9 or 10 are regarded as \"promoters\"\n",
    "\n",
    "The final NPS score for a given period is calculated as the percentage of total users who are promoters minus the percentage of total users who are detractors. This means that an NPS score can be anything from -100 to 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: (5 min)\n",
    "\n",
    "If you have the following scores left by your customers:\n",
    "\n",
    "| Date           | CustomerId | Score | Group     |\n",
    "| -------------- | ---------- | ----- | --------- |\n",
    "| 1 January 2018 | 562        | 1     | Detractor |\n",
    "| 1 January 2018 | 544        | 10    | Promoter  |\n",
    "| 2 January 2018 | 333        | 9     | Promoter  |\n",
    "| 2 January 2018 | 102        | 9     | Promoter  |\n",
    "| 4 January 2018 | 267        | 9     | Promoter  |\n",
    "| 5 January 2018 | 981        | 10    | Promoter  |\n",
    "| 6 January 2018 | 105        | 6     | Detractor |\n",
    "| 6 January 2018 | 459        | 7     | Passive   |\n",
    "| 6 January 2018 | 188        | 10    | Promoter  |\n",
    "| 8 January 2018 | 982        | 8     | Passive   |\n",
    "\n",
    "What is your NPS? How would you adjust your calculation of NPS if instead users had many opportunities to rate you in a short time period? What would you consider to be a \"good\" NPS? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** We have 10 responses: 6 promoters, 2 detractors and 2 passives. That is 60% promoters and 20% detractors, so our NPS is $60 - 20 = 40$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If users could rate us many times in a short time span, a sensible adjustment would be to first average all of the responses per user, and use this averaged response to group each user into promoter, detractor, or passive. This is because no matter how many times a single user interacts with our product, they are likely still only paying us once for it. Thus, since they are not weighted more heavily in our revenue streams, they should not be weighted more heavily in our customer satisfaction schemes either.\n",
    "\n",
    "Defining what constitutes a good NPS depends on the specific line of business the company is in. It varies between [different industries](https://www.qualtrics.com/marketplace/nps-benchmarks/) with internet providers generally getting far lower scores than technology companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a cloud database using RDS and importing data (30 min)\n",
    "\n",
    "Ok! Let's set up a database and load in some NPS data so that we can analyze it using SQL. We'll use the code at [this repository](https://github.com/sixhobbits/nps-sample-data) to generate a large sample of fake NPS data and push it into a PostgreSQL instance running in the cloud. (Don't look at the source code that generates the data, as it will spoil the fun.)\n",
    "\n",
    "1. Log into your AWS account and select \"RDS\" from the service list. You should see a screen like the one below, where you can hit the \"Create database\" button:\n",
    "\n",
    "![Create Database](images/create_db.png)\n",
    "\n",
    "2. The next option you'll see asks you if you want to use \"standard create\" or \"easy create\". Easy might sound tempting, but **choose \"standard\"** as we'll have to set up our database for public use so we can connect to it locally.\n",
    "\n",
    "3. Choose \"PostgreSQL\" as the database type, leave the version at the default AWS has chosen for you (10.6-R1 at the time of writing), and choose \"Free Tier\"\n",
    "\n",
    "4. Under the next section, choose a name for your database instance. Remember this is the machine that is hosting the database software, not the database itself (one RDS instance can host many databases), so I'm calling mine `nps-demo-instance` to reflect this, although we'll only be creating a single database for now. \n",
    "\n",
    "5. You can leave the master username as `postgres` and ask RDS to autogenerate a password (we'll be able to see this password at the next step):\n",
    "\n",
    "![Set DB password](images/set_db_password.png)\n",
    "\n",
    "6. You can leave the next settings as their defaults until you get to the \"Connectivity\" section. Usually, you'll set up an RDS instance to play with other infrastructure within your AWS account, such as EC2 servers. In our case, we want to push data in and out of the database directly from our local machine as the client, so we'll have to set our database up for \"public access\". This is generally less secure, but we'll add some firewall rules in a bit to make sure that only we can access it:\n",
    "\n",
    "      * Expand the \"Additional connectivity configuration\" section\n",
    "\n",
    "      * Set \"publicly accessible\" to \"Yes\"\n",
    "\n",
    "      * Under \"VPC security group\", choose to \"Create new\", and give it a name like `allow-local-access`. This will create a firewall rule that will allow you to connect to your database on port 5432 (the default for PostgreSQL) using your current IP address. If you are using public WiFi, a hotspot, or if you think your IP address is likely to change soon for any reason, note that you'll have to modify this security group any time your IP address changes:\n",
    "\n",
    "![Create Security Group](images/create-sec-group.png)\n",
    "\n",
    "7. Press the \"Create database\" button in the bottom right, and you'll be taken back to the overview page where you can see your database being created. At the top, there'll be a notification where you can press \"View credential details\" to access your master password that was automatically generated. Take note of this as you can only see it once. NOTE: this creates a database in the default VPC. If your default VPC is not configured for DNS connections, you will need to create a new VPC. Please see 'Appendix 1: Troubleshooting RDS creation' for instructions on how to do achieve this.\n",
    "\n",
    "![View credentials](images/view_creds.png)\n",
    "\n",
    "8. Once your database becomes \"available\" (you might need to press the \"refresh\" button indicated below to see the change), you can connect to it. Click on the name of the database (`nps-demo-instance` in our example), to find out the connection details:\n",
    "\n",
    "![DB available](images/db-available.png)\n",
    "\n",
    "9. Once you click on the database, you should see the endpoint that you need on a screen similar to the one shown below. You need this endpoint to connect to the database from your local machine.\n",
    "\n",
    "![DB Endpoint](images/db-endpoint.png)\n",
    "\n",
    "10. Locally, open a terminal and run the following command, substituting [endpoint] with the one that you noted from the RDS console above.\n",
    "\n",
    "```bash\n",
    "psql -h [endpoint] -U postgres\n",
    "```\n",
    "\n",
    "This will connect to our instance's default database using the master username. It will prompt you for the password and you can enter the autogenerated password from above. You should now see a SQL prompt, similar to the image below:\n",
    "\n",
    "![PSQL prompt](images/psql-prompt.png)\n",
    "\n",
    "We've successfully created a cloud database and connected to it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up our NPS database (10 min)\n",
    "\n",
    "Let's proceed by setting up our database in Amazon RDS:\n",
    "\n",
    "1. In the SQL shell, run the following commands to create a database, create a user to manage our database, and give privileges on our new database to our new user. Replace [password] with your own choice of password:\n",
    "\n",
    "```SQL\n",
    "create database nps_demo_db;\n",
    "create user nps_demo_user with login encrypted password '[password]';\n",
    "grant all privileges on database nps_demo_db to nps_demo_user;\n",
    "\\q\n",
    "```\n",
    "\n",
    "Here, `\\q` closes the connection so you can re-open it under a different user.\n",
    "\n",
    "2. Run the following command. It is similar to the one we used before to connect but now specifies both our custom user and our custom database. Once again, substitute [endpoint] with the one you see in the RDS console.\n",
    "\n",
    "```SQL\n",
    "psql -h [endpoint] -U nps_demo_user -d nps_demo_db\n",
    "```\n",
    "\n",
    "3. Put in the new password that you entered in the SQL statement in step 1 instead of the master password that AWS automatically generated for us.  You'll see a very similar prompt, but with the `nps_demo_db=>` prompt instead of `postgres=>`:\n",
    "\n",
    "![nps demo prompt](images/nps-demo-prompt.png)\n",
    "\n",
    "The next thing we need to do is to create tables to house our data. We'll use the data from [this repository](https://github.com/sixhobbits/nps-sample-data/), consisting of two tables: `customer` and `score`. There are some extra fields on `customer` (`is_premier` and `is_spam`) that we won't use right away, but we'll create our tables to match that format anyway to make the import easier.\n",
    "\n",
    "The important context is that we are imagining a scenario where:\n",
    "\n",
    "* We have been running a new company for around one year.\n",
    "* The product has gone through different stages of feature improvement and stability but has overall shown growth and improvement.\n",
    "* Every day, new customers join and both new and old customers may or may not leave us a score between 0-10 to rate how likely they are to recommend our product to family and friends.\n",
    "* At the start and at some key points during the year, the product is unstable or lacking features and this affects the customer rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets use SQL to create two tables: one for customers, and one for the scores that our customers leave.\n",
    "\n",
    "To create the `customer` table, we do the following:\n",
    "\n",
    "```SQL\n",
    "create table customer (id serial not null, created_at date, is_premier boolean, is_spam boolean, CONSTRAINT customer_pkey PRIMARY KEY (id));\n",
    "```\n",
    "\n",
    "This creates a `customer` table with an ID, the date the customer first signed up (`created_at`), and two boolean flags that we don't need yet. It also adds a constraint to the ID field saying it is a primary key, meaning it has to be unique. \n",
    "\n",
    "\n",
    "To create the table of scores that our customers leave, use the following command in the same prompt:\n",
    "\n",
    "```SQL\n",
    "create table score (id serial not null, customer_id integer references customer(id), created_at date, score integer, CONSTRAINT scores_pkey PRIMARY KEY (id));\n",
    "```\n",
    "\n",
    "This is similar to the `customer` table, but has a `score` field to store the value between 0 and 10 that a customer leaves each time they complete a survey, and another date field to record when the survey was done. There is also a foreign key `customer_id` to link each score to a specific entity in the `customer` table. \n",
    "\n",
    "You can close the connection again with `\\q`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pushing sample data into RDS (10 min)\n",
    "\n",
    "Let's now push the NPS data onto RDS:\n",
    "\n",
    "1. Download the two CSV files (`score.csv` and `customer.csv`) from https://github.com/sixhobbits/nps-sample-data into your local working directory. Don't look at the README file.\n",
    "\n",
    "2. Run the command below, again substituting [endpoint] with the actual endpoint you used above. Make sure that the `customer.csv` file is located in the same directory that you run the `psql` command from:\n",
    "\n",
    "```bash\n",
    "psql -h [endpoint] -U nps_demo_user -d nps_demo_db -c \"\\copy customer from 'customer.csv' with (format csv, header true, delimiter ',');\"\n",
    "```\n",
    "\n",
    "The first part of the command is the same one we used before to open a SQL shell. Here we also pass the `-c` flag which allows us to specify a SQL command to be run on the database. Because our shell has permissions to access our local file system, but our database doesn't, running the command like this means we won't have problems with permissions. In the `\\copy` command, we specify which table we want to populate (`customer`), where the local file is (`customer.csv`), that our file is in CSV format, that it has a header, and that we are using a comma as a delimiter. \n",
    "\n",
    "This should prompt you for the password (again, use the one that you created for the `nps_demo_user`). It will then let you know how many rows it has successfully imported, similar to the image below:\n",
    "\n",
    "![Copy successful](images/copy-successful.png)\n",
    "\n",
    "3. Now we can add the scores data as well using the same method. The only things we need to change are the table name and the filename from which we source the data. The full command (don't forget to substitute your endpoint) is:\n",
    "\n",
    "```bash\n",
    "psql -h [endpoint] -U nps_demo_user -d nps_demo_db -c \"\\copy score from 'score.csv' with (format csv, header true, delimiter ',');\"\n",
    "```\n",
    "\n",
    "There are a lot more sample scores than customers (as each customer can respond to the survey more than once), so this will take a bit longer than the previous command:\n",
    "\n",
    "![Import scores](images/import-scores.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing our NPS data using SQL (40 min)\n",
    "\n",
    "Now we can proceed to the fun part. We have NPS scores left by a large number of customers over the past year, and we want to see how these scores change over time.\n",
    "\n",
    "We only have raw data – numbers between 0 and 10 inclusive – so we'll use SQL to group this data in different ways and transform it into NPS data. If you remember how to define NPS from the first section, you can probably work out that the main things we need to do are:\n",
    "\n",
    "1. Break down our scores per customer for any given time period (here, we will look at this per week)\n",
    "2. Divide customers into promoters, passives or detractors, based on the scores they have left in that week\n",
    "3. Calculate the NPS per week and look at how this value changes week-by-week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting customers and scores (10 min)\n",
    "\n",
    "We saw how many customers and scores we had when we did the import step above. However, in a real-world setting, you would have gathered this data slowly, over time, so let's start by counting out customers, our survey responses (`scores`), and looking at how many surveys each customer responds to. For each of the following, you'll need to be connected to the SQL shell, so run the following first (using your endpoint) and any time you need to.\n",
    "\n",
    "We'll show the output of each SQL command directly below – you only need to enter the command shown in the first section in each of the following examples.\n",
    "\n",
    "```bash\n",
    "psql -h [endpoint] -U nps_demo_user -d nps_demo_db\n",
    "```\n",
    "\n",
    "#### Counting customers\n",
    "\n",
    "```SQL\n",
    "SELECT COUNT(*) FROM customer;\n",
    "```\n",
    "\n",
    "```\n",
    " count\n",
    "--------\n",
    " 188323\n",
    "(1 row)\n",
    "```\n",
    "\n",
    "We have nearly 200k customers, which is not bad for a product that's been running for one year!\n",
    "\n",
    "#### Counting scores\n",
    "\n",
    "```SQL\n",
    "SELECT COUNT(*) FROM score;\n",
    "```\n",
    "\n",
    "```\n",
    "  count\n",
    "---------\n",
    " 1577578\n",
    "(1 row)\n",
    "```\n",
    "\n",
    "And we have over 1.5 million survey responses. That's just over 8 responses per customer if we assume an equal distribution. Let's use SQL to look at that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9: (5 min)\n",
    "\n",
    "Write a SQL query that outputs a table showing the 10 customers with the highest number of responses and their total response count, in descending order (customer with most responses at the top)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT customer_id, COUNT(score.id) AS cnt FROM score\n",
    "INNER JOIN customer ON customer_id = customer.id\n",
    "GROUP BY customer_id ORDER BY cnt DESC\n",
    "LIMIT 10;\n",
    "```\n",
    "\n",
    "```\n",
    " customer_id | count\n",
    "-------------+-------\n",
    "          31 |    38\n",
    "         928 |    38\n",
    "        4271 |    38\n",
    "        5333 |    37\n",
    "        1253 |    37\n",
    "        1259 |    36\n",
    "        1030 |    36\n",
    "        2327 |    36\n",
    "         564 |    36\n",
    "        2335 |    36\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use SQL JOINs using commas and a `WHERE` clause as a shortcut. The above command is equivalent to the following one, but the earlier version is preferable in most contexts as it is more explicit:\n",
    "\n",
    "```SQL\n",
    "SELECT customer_id, COUNT(score.id) AS cnt FROM score, customer\n",
    "WHERE customer_id = customer.id\n",
    "GROUP BY customer_id ORDER BY cnt DESC\n",
    "LIMIT 10;\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "We can also look at customers who have left very few responses by ordering by `ASC` instead of `DESC`:\n",
    "\n",
    "```SQL\n",
    "SELECT customer_id, COUNT(score.id) AS cnt FROM score\n",
    "INNER JOIN customer ON customer_id = customer.id\n",
    "GROUP BY customer_id ORDER BY cnt ASC\n",
    "LIMIT 10;\n",
    "```\n",
    "\n",
    "```\n",
    " customer_id | cnt\n",
    "-------------+-----\n",
    "       57565 |   1\n",
    "       62357 |   1\n",
    "       49021 |   1\n",
    "       57424 |   1\n",
    "       61891 |   1\n",
    "       62295 |   1\n",
    "       44796 |   1\n",
    "       44995 |   1\n",
    "       57286 |   1\n",
    "       62402 |   1\n",
    "```\n",
    "\n",
    "We can see there are at least 10 customers who have left only a single response. Let's do a 'count of counts' query to get a better idea of how many responses most customers leave. We want to count how many customers have left exactly $x$ responses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10: (5 min)\n",
    "\n",
    "Write a SQL query that outputs a table showing how many customers leave $x$ responses for any given integer $x$. Sort this table in descending order ($x$ with highest number of customers leaving $x$ responses at the top).\n",
    "\n",
    "(Hint: Use a **nested** `SELECT` statement. A nested statement is when you treat the results of one query as the input to another one.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT cnt, COUNT(cnt) as count_of_count FROM\n",
    "(SELECT customer_id, count(score.id) AS cnt FROM score\n",
    "INNER JOIN customer ON customer_id = customer.id\n",
    "GROUP BY customer_id ) a\n",
    "GROUP BY cnt\n",
    "ORDER BY count_of_count DESC\n",
    "LIMIT 100;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in the query above we have taken a query very similar to the one from Exercise 10 and nested it in parentheses. We have then given this intermediate query an **alias**, which comes immediately after the closing parenthesis; in this case we have chosen the alias `a`. It is a common convention to use aliases `a`, `b`, `c`, etc. as a shorthand if you are primarily interested only in the final result.\n",
    "\n",
    "From our previous queries, we already know that all the values have to fall between 1 and 38, so there can be a maximum of 38 rows returned in this query. Therefore there is no real need to add a LIMIT clause, but we add a `LIMIT 100` anyway. This is a good habit in case you make a wrong assumption to prevent the case where you accidentally try to pull thousands or millions of rows from a remote server. For brevity, we only included the first 15 rows of output below:\n",
    "\n",
    "```\n",
    " cnt | count_of_count\n",
    "-----+----------------\n",
    "   6 |          18779\n",
    "   5 |          17218\n",
    "   7 |          17094\n",
    "   4 |          15642\n",
    "   8 |          14108\n",
    "   3 |          12983\n",
    "   9 |          11978\n",
    "  10 |          10556\n",
    "   2 |          10191\n",
    "  11 |           9001\n",
    "  12 |           7833\n",
    "  13 |           6698\n",
    "   1 |           6302\n",
    "  14 |           5707\n",
    "  15 |           4908\n",
    "```\n",
    "\n",
    "We can see that most customers leave between 2 and 10 responses so the maximum of 38 is an outlier. A fair number of people only leave one response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average scores per week (10 min)\n",
    "\n",
    "However, we still have not looked at how scores are *changing*. Let's average all scores in each week and see how the scores go up and down over time:\n",
    "\n",
    "```SQL\n",
    "SELECT TO_CHAR(score.created_at, 'IYYY-IW') AS week, AVG(score) AS avg_score\n",
    "FROM score\n",
    "GROUP BY week\n",
    "ORDER BY week ASC\n",
    "LIMIT 100;\n",
    "```\n",
    "\n",
    "Again, we did not need to add a limit clause as we know there will only be 52 rows (the number of weeks in a year, which is the span of our dataset), but we do anyway for good measure and again include only the first 15 rows of output below:\n",
    "\n",
    "```\n",
    "  week   |     avg_score\n",
    "---------+--------------------\n",
    " 2018-01 | 5.3618090452261307\n",
    " 2018-02 | 6.1577181208053691\n",
    " 2018-03 | 5.1405228758169935\n",
    " 2018-04 | 5.2256097560975610\n",
    " 2018-05 | 6.3962765957446809\n",
    " 2018-06 | 7.2065359477124183\n",
    " 2018-07 | 7.0110294117647059\n",
    " 2018-08 | 6.9827490261547023\n",
    " 2018-09 | 7.4689516129032258\n",
    " 2018-10 | 7.9564362001124227\n",
    " 2018-11 | 8.0201993704092340\n",
    " 2018-12 | 7.8336310283235519\n",
    " 2018-13 | 7.9298795180722892\n",
    " 2018-14 | 7.9583184257602862\n",
    " 2018-15 | 7.9876211782252051\n",
    "```\n",
    "\n",
    "We can see that the scores start low and generally trend up over time, although they go down again around week 36 (not shown above). We use the [ISO Week](https://en.wikipedia.org/wiki/ISO_week_date) through PostgreSQL's `TO_CHAR` function to break down each of our dates into a specific week number and average the scores per week. \n",
    "\n",
    "There are a couple issues with the above query, though:\n",
    "\n",
    "1. The `AVG` function shows a lot of decimal points by default which makes it more difficult to read the data\n",
    "2. Many customers leave a different number of responses and some might leave more than one response per week\n",
    "\n",
    "A good compromise is to calculate the average score per customer per week, then average all of these to get an average score across all customers per week. Let's do this and round off some decimal points to make our data easier to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11: (5 min)\n",
    "\n",
    "Write a query to compute the average score across all customers per week, rounding off to two decimal places. (Hint: Use the `ROUND()` function, which takes two arguments: the quantity you are rounding, and how many decimals you are rounding off to.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT week, ROUND(AVG(avg_week_score),2) as avg_score FROM\n",
    "(SELECT TO_CHAR(score.created_at, 'IYYY-IW') AS week, customer_id, AVG(score) as avg_week_score FROM score\n",
    "GROUP BY week, customer_id) a\n",
    "GROUP BY week\n",
    "ORDER BY week\n",
    "LIMIT 100;\n",
    "```\n",
    "\n",
    "```\n",
    " week   | avg_score\n",
    "---------+-----------\n",
    " 2018-01 |      5.12\n",
    " 2018-02 |      5.80\n",
    " 2018-03 |      5.74\n",
    " 2018-04 |      5.50\n",
    " 2018-05 |      6.33\n",
    " 2018-06 |      7.02\n",
    " 2018-07 |      7.01\n",
    " 2018-08 |      6.89\n",
    " 2018-09 |      7.38\n",
    " 2018-10 |      7.75\n",
    " 2018-11 |      7.80\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying our customers as promoters, passives, or detractors (10 min)\n",
    "\n",
    "Now, let's proceed to classifying our customers so we can calculate the NPS per week. We used a similar `SELECT` (two deep this time!) and a `CASE` statement. The `CASE` keyword acts as an if statement and returns specific values in specific cases. For us, anything larger than an 8 (i.e. 9 or 10) is a promoter, otherwise, anything larger than a 6 (i.e. 7 or 8) is a passive and everything else is a detractor:\n",
    "\n",
    "```SQL\n",
    "SELECT * FROM\n",
    "(SELECT CASE\n",
    "    WHEN avg_week_score > 8 THEN 'promoter'\n",
    "    WHEN avg_week_score > 6 THEN 'passive'\n",
    "    ELSE 'detractor'\n",
    "END AS nps_class, week FROM\n",
    "(SELECT TO_CHAR(score.created_at, 'IYYY-IW') AS week, customer_id, AVG(score) as avg_week_score FROM score\n",
    "GROUP BY week, customer_id) a) b\n",
    "limit 10;\n",
    "```\n",
    "\n",
    "Which gives us the following output: a huge table with the nps_class and the week number:\n",
    "\n",
    "```\n",
    " nps_class |  week\n",
    "-----------+---------\n",
    " detractor | 2018-01\n",
    " detractor | 2018-01\n",
    " promoter  | 2018-01\n",
    " detractor | 2018-01\n",
    " promoter  | 2018-01\n",
    " detractor | 2018-01\n",
    " detractor | 2018-01\n",
    " detractor | 2018-01\n",
    " detractor | 2018-01\n",
    " promoter  | 2018-01\n",
    "```\n",
    "\n",
    "This is closer to what we need, but not very useful in its current form. We can confirm that there are still nearly a million rows by using another `COUNT`:\n",
    "\n",
    "```SQL\n",
    "SELECT count(*) FROM\n",
    "(SELECT CASE\n",
    "    WHEN avg_week_score > 8 THEN 'promoter'\n",
    "    WHEN avg_week_score > 6 THEN 'passive'\n",
    "    ELSE 'detractor'\n",
    "END AS nps_class, week FROM\n",
    "(SELECT TO_CHAR(score.created_at, 'IYYY-IW') AS week, customer_id, AVG(score) as avg_week_score FROM score\n",
    "GROUP BY week, customer_id) a) b\n",
    "limit 10;\n",
    "```\n",
    "\n",
    "```\n",
    " count\n",
    "--------\n",
    " 951289\n",
    "(1 row)\n",
    "```\n",
    "\n",
    "Now that we've broken our customers into specific categories, we want to count them. It's useful to \"pivot\" this data so that we can see the count of each class of people as a separate column. In a spreadsheet program like Microsoft Excel or Google Sheets, we would think of this as a pivot table, and there are plugins for PostgreSQL to allow you to use it in a similar way. In our case, though, we can count the number of each class each week using some more `CASE` statements and the `SUM` function as follows:\n",
    "\n",
    "```SQL\n",
    "SELECT week,\n",
    "SUM(CASE WHEN nps_class = 'promoter' THEN 1 ELSE 0 END) AS \"promoter\",\n",
    "SUM(CASE WHEN nps_class = 'passive' THEN 1 ELSE 0 END) AS \"passive\",\n",
    "SUM(CASE WHEN nps_class = 'detractor' THEN 1 ELSE 0 END) AS \"detractor\",\n",
    "    COUNT(*) AS \"total\" FROM\n",
    "(SELECT CASE\n",
    "    WHEN avg_week_score > 8 THEN 'promoter'\n",
    "    WHEN avg_week_score > 6 THEN 'passive'\n",
    "    ELSE 'detractor'\n",
    "END AS nps_class, week FROM\n",
    "(SELECT TO_CHAR(score.created_at, 'IYYY-IW') AS week, customer_id, AVG(score) as avg_week_score FROM score\n",
    "GROUP BY week, customer_id) a) b\n",
    "GROUP BY week\n",
    "ORDER BY week\n",
    "limit 100;\n",
    "```\n",
    "\n",
    "Which results in (truncated for brevity):\n",
    "\n",
    "```\n",
    "  week   | promoter | passive | detractor | total\n",
    "---------+----------+---------+-----------+-------\n",
    " 2018-01 |       26 |       0 |        39 |    65\n",
    " 2018-02 |       65 |       2 |        63 |   130\n",
    " 2018-03 |       71 |       7 |        70 |   148\n",
    " 2018-04 |       76 |       6 |        83 |   165\n",
    " 2018-05 |      186 |      23 |       135 |   344\n",
    " 2018-06 |      397 |      56 |       202 |   655\n",
    " 2018-07 |      471 |      72 |       238 |   781\n",
    " 2018-08 |      520 |      79 |       276 |   875\n",
    " 2018-09 |      771 |     102 |       300 |  1173\n",
    " 2018-10 |     1154 |     154 |       351 |  1659\n",
    " ...\n",
    "```\n",
    "\n",
    "Note that we also had to add another intermediate alias (`b`) to our SQL code, as we have yet another level of nested `SELECT`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating NPS per week (10 min)\n",
    "\n",
    "We now have all the pieces in place to calculate our NPS. To do this, we will have to use a *third* nested `SELECT` and yet another table alias `c`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12: (10 min)\n",
    "\n",
    "Given the above guidance, write the query to compute NPS per week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT *, ROUND(((CAST(promoter AS DECIMAL) / total) - (CAST(detractor AS DECIMAL) / total)) * 100, 0) AS nps FROM\n",
    "(SELECT week,\n",
    "SUM(CASE WHEN nps_class = 'promoter' THEN 1 ELSE 0 END) AS \"promoter\",\n",
    "SUM(CASE WHEN nps_class = 'passive' THEN 1 ELSE 0 END) AS \"passive\",\n",
    "SUM(CASE WHEN nps_class = 'detractor' THEN 1 ELSE 0 END) AS \"detractor\",\n",
    "    COUNT(*) AS \"total\" FROM\n",
    "(SELECT CASE\n",
    "    WHEN avg_week_score > 8 THEN 'promoter'\n",
    "    WHEN avg_week_score > 6 THEN 'passive'\n",
    "    ELSE 'detractor'\n",
    "END AS nps_class, week FROM\n",
    "(SELECT TO_CHAR(score.created_at, 'IYYY-IW') AS week, customer_id, AVG(score) as avg_week_score FROM score\n",
    "GROUP BY week, customer_id) a) b\n",
    "GROUP BY week\n",
    "ORDER BY week) c\n",
    "limit 100;\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "  week   | promoter | passive | detractor | total | nps\n",
    "---------+----------+---------+-----------+-------+-----\n",
    " 2018-01 |       26 |       0 |        39 |    65 | -20\n",
    " 2018-02 |       65 |       2 |        63 |   130 |   2\n",
    " 2018-03 |       71 |       7 |        70 |   148 |   1\n",
    " 2018-04 |       76 |       6 |        83 |   165 |  -4\n",
    " 2018-05 |      186 |      23 |       135 |   344 |  15\n",
    " 2018-06 |      397 |      56 |       202 |   655 |  30\n",
    " 2018-07 |      471 |      72 |       238 |   781 |  30\n",
    " 2018-08 |      520 |      79 |       276 |   875 |  28\n",
    " 2018-09 |      771 |     102 |       300 |  1173 |  40\n",
    " 2018-10 |     1154 |     154 |       351 |  1659 |  48\n",
    " 2018-11 |     1313 |     180 |       394 |  1887 |  49\n",
    " 2018-12 |     1419 |     204 |       423 |  2046 |  49\n",
    "```\n",
    "\n",
    "That first line is not pretty, but it works! We can now see the NPS, correctly rounded, for any given week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions (5 min)\n",
    "\n",
    "In the first part of this case, you learned the basics of SQL and used it to optimize the sales operations of a financial services firm. We narrowed down our set of potentially interesting customer cohorts and were able to compute summary statistics on the sales conversion rates of those cohorts, particularly versus the mean. In particular, we learned that some of our \"no-brainer\" hypotheses did not pan out, which illustrates the importance of always investigating the data to validate our thoughts.\n",
    "\n",
    "In the second part of this case, you learned about the Net Promoter Score (NPS) metric. You set up a cloud database using Amazon RDS, a service that makes it easy to manage and scale your databases with little to no work from your local machine. You also learned how to write complex queries in SQL that could be run directly on the cloud database. These queries used advanced features like nested `SELECT` statements and `CASE` statements which can be combined in intricate ways to get the results you need directly from your database.\n",
    "\n",
    "We found that there was a general increase in NPS over time; however, starting in September there was a significant downturn in average NPS score. It is likely that the product encountered some significant bugs or outages during this time and going forward we should check if anything was recorded by the startup's product team to confirm this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways (5 min)\n",
    "\n",
    "SQL is a powerful tool that can help us navigate and understand data in ways that Python cannot. Sometimes, it can even serve as the first stage of an exploratory data analysis and can sometimes help us answer questions all by itself. Furthermore, SQL is the means through which we can create and persist data in databases for future, large-scale use. No data scientist's toolkit is complete without an understanding of how to interface with and store the raw data that they work with.\n",
    "\n",
    "Additionally, cloud databases are a powerful and scalable way to analyze data if you have constraints on processor, memory or storage resources for your local hardware. You can do all sorts of things in-cloud that you could originally only do on your local machine, such as run complex SQL queries directly against a cloud database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 1: Troubleshooting RDS creation\n",
    "\n",
    "If you cannot create your database using the RDS service and instead see the error below, you will need to create a new VPC instead of using the default one. \n",
    "\n",
    "![vpc dns error](images/vpc-rds-error.png)\n",
    "\n",
    "\n",
    "To do this, scroll back up to the 'Connectivity' section, and choose 'create new VPC' from the dropdown as shown in the image below\n",
    "\n",
    "![create new vpc](images/create-new-vpc.png)\n",
    "\n",
    "At the bottom of the page, press \"Create Database\" again, and you should see a notification briefly at the top of the page that confirms a new VPC has been created, as in the image below. Take a note of the ID.\n",
    "\n",
    "![view vpc](images/view-vpc-id.png)\n",
    "\n",
    "You might now see another error, as follows. This is because the VPC created from the RDS console has no name.\n",
    "\n",
    "![vpc no name error](images/vpc-no-name-error.png)\n",
    "\n",
    "\n",
    "If this is the case, you need to name your VPC. From the services dropdown at the top of the page, search for \"VPC\" and open the VPC page in a new tab.\n",
    "\n",
    "\n",
    "![view VPCs](images/services-select-vpc.png)\n",
    "\n",
    "Find the VPC that was recently created (it will have the same ID as the one you noted above). Mouse over the 'name' field to see the pencil 'edit' option appear, click on this, and give the VPC a name.\n",
    "\n",
    "\n",
    "![name VPC](images/name-vpc.png)\n",
    "\n",
    "Now that your VPC has a name, go back to the tab where you are creating the RDS instance, and scroll back up to the connectivity section, and choose the newly created VPC (you will see the name you chose displayed) from the dropdown.\n",
    "\n",
    "Now you can finally press \"Create database\" again (at the bottom of the page) and all should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
